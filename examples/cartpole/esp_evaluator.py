"""
Evaluator for the CartPole gymnasium environment using the ESP outer loop.
"""
import gymnasium
import numpy as np
from sklearn.ensemble import RandomForestRegressor
import torch

from presp.evaluator import Evaluator
from presp.prescriptor import NNPrescriptor


class Dataset():
    def __init__(self, d_context, d_actions, d_outcomes):
        self.d_context = d_context
        self.d_actions = d_actions
        self.d_outcomes = d_outcomes

        self.data = None

    def add(self, gen: int, context: np.ndarray, actions: np.ndarray, outcomes: np.ndarray):
        iter_col = np.full((context.shape[0], 1), gen)
        step_col = np.arange(0, context.shape[0]).reshape(-1, 1)
        rollout_array = np.concatenate([iter_col, step_col, context, actions, outcomes], axis=1)
        if self.data is None:
            self.data = rollout_array
        else:
            self.data = np.concatenate([self.data, rollout_array], axis=0)

    def get_sklearn_data(self):
        return self.data[:, 2:-self.d_outcomes], self.data[:, -self.d_outcomes:]

    def get_torch_data(self):
        context = self.data[:, 2:2 + self.d_context]
        return torch.tensor(context, dtype=torch.float32)


class ESPEvaluator(Evaluator):
    """
    Evaluator implementation for the CartPole gymnasium environment using the outer loop in ESP.
    Every generation, we re-train the predictor on rollouts generated by the elites.
    """
    def __init__(self, n_jobs: int, n_envs: int):
        super().__init__(outcomes=["score"], n_jobs=n_jobs)
        self.n_envs = n_envs
        self.gen = 0
        self.dataset = Dataset(4, 1, 1)
        self.predictor = RandomForestRegressor()

    def update_predictor(self, elites: list[NNPrescriptor]):
        for elite in elites:
            contexts, actions, outcomes = self.run_rollout(elite)
            self.dataset.add(self.gen, contexts, actions, outcomes)

        X, y = self.dataset.get_sklearn_data()
        self.predictor.fit(X, y.ravel())

        self.gen += 1

    def run_rollout(self, candidate: NNPrescriptor):
        contexts = []
        actions = []
        outcomes = []
        for i in range(self.n_envs):
            env = gymnasium.make("CartPole-v1")
            obs, _ = env.reset(seed=i)
            episode_over = False
            while not episode_over:
                # Get action from an observation using the candidate model.
                # If the candidate is None, we randomly select from the action space.
                if candidate is None:
                    action = env.action_space.sample()
                else:
                    obs_tensor = torch.tensor(obs, dtype=torch.float32, device=candidate.device)
                    prob = candidate.forward(obs_tensor)
                    action = (prob > 0.5).int()

                # Perform gymnasium step
                next_obs, reward, done, truncated, _ = env.step(action.item())

                # Log CAO for ESP
                contexts.append(obs)
                actions.append(action.item())
                outcomes.append(reward)

                # Check if done, set next obs
                episode_over = done or truncated
                obs = next_obs

            env.close()

        # Preprocess rollout then add it to dataset
        contexts = np.array(contexts)
        actions = np.array(actions).reshape(-1, 1)
        outcomes = np.array(outcomes).reshape(-1, 1)
        return contexts, actions, outcomes

    def evaluate_candidate(self, candidate: NNPrescriptor):
        with torch.no_grad():
            context = self.dataset.get_torch_data()
            actions = candidate.forward(context)
            X = np.concatenate([context.cpu().numpy(), actions.cpu().numpy()], axis=1)
            outcomes = self.predictor.predict(X)
        return np.array([-1 * np.mean(outcomes)])
